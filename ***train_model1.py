import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import os
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, confusion_matrix
from sklearn.preprocessing import StandardScaler  # <--- (‡πÉ‡∏´‡∏°‡πà) ‡∏ï‡∏±‡∏ß‡∏ä‡πà‡∏ß‡∏¢‡∏õ‡∏£‡∏±‡∏ö‡∏™‡πÄ‡∏Å‡∏•‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout, LSTM, Conv1D, MaxPooling1D
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.utils import to_categorical
from tensorflow.keras.callbacks import ReduceLROnPlateau # <--- (‡πÉ‡∏´‡∏°‡πà) ‡∏ï‡∏±‡∏ß‡∏ä‡πà‡∏ß‡∏¢‡∏•‡∏î LR ‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥

# üî• ‡πÄ‡∏£‡∏µ‡∏¢‡∏Å‡πÉ‡∏ä‡πâ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏à‡∏≤‡∏Å‡πÑ‡∏ü‡∏•‡πå data_loader.py (‡πÉ‡∏ä‡πâ‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏î‡∏¥‡∏°‡πÑ‡∏î‡πâ‡πÄ‡∏•‡∏¢)
from data_loader import load_data

# ==========================================
# 1. CONFIGURATION (‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤)
# ==========================================
# Path ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• (‡πÅ‡∏Å‡πâ‡πÉ‡∏´‡πâ‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á ‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏ä‡πà‡∏≠‡∏á‡∏ß‡πà‡∏≤‡∏á‡∏ô‡∏≥‡∏´‡∏ô‡πâ‡∏≤)
ROOT_DIR = r"D:\Data Movement\CollectDATA\Subject"
OUTPUT_DIR = r"D:\Data Movement\CollectDATA\Model"

WINDOW_SIZE = 128
STEP_SIZE = 64
BATCH_SIZE = 32
EPOCHS = 60           # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏£‡∏≠‡∏ö‡∏´‡∏ô‡πà‡∏≠‡∏¢ ‡πÄ‡∏û‡∏£‡∏≤‡∏∞‡πÄ‡∏£‡∏≤‡∏à‡∏∞‡πÉ‡∏´‡πâ‡∏°‡∏±‡∏ô‡∏Ñ‡πà‡∏≠‡∏¢‡πÜ ‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ
LEARNING_RATE = 0.001
CLASSES = ['Low Risk', 'Medium Risk', 'High Risk']

# ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå Output ‡∏ñ‡πâ‡∏≤‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏°‡∏µ
if not os.path.exists(OUTPUT_DIR):
    os.makedirs(OUTPUT_DIR)
    print(f"üìÇ ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡πÉ‡∏´‡∏°‡πà: {OUTPUT_DIR}")

# ==========================================
# 2. DATA PREPARATION & NORMALIZATION
# ==========================================
print("üîÑ Loading Data...")
X, y = load_data(ROOT_DIR, WINDOW_SIZE, STEP_SIZE)

if len(X) == 0:
    print("‚ùå ‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•! ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö Path ‡∏´‡∏£‡∏∑‡∏≠‡∏ä‡∏∑‡πà‡∏≠‡πÑ‡∏ü‡∏•‡πå")
    exit()

# ‡πÅ‡∏õ‡∏•‡∏á Label ‡πÄ‡∏õ‡πá‡∏ô One-Hot
y_onehot = to_categorical(y, num_classes=3)

# ‡πÅ‡∏ö‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• Train / Test
X_train, X_test, y_train, y_test = train_test_split(X, y_onehot, test_size=0.2, random_state=42, stratify=y)

print(f"üìä Training Data (Raw): {X_train.shape}")

# üî•üî•üî• (‡πÉ‡∏´‡∏°‡πà) ‡∏™‡πà‡∏ß‡∏ô‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç: NORMALIZATION üî•üî•üî•
# ‡∏õ‡∏£‡∏±‡∏ö‡∏™‡πÄ‡∏Å‡∏•‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏´‡πâ‡πÄ‡∏õ‡πá‡∏ô‡∏°‡∏≤‡∏ï‡∏£‡∏ê‡∏≤‡∏ô‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Å‡∏±‡∏ô (Mean=0, Std=1) 
# ‡∏à‡∏∞‡∏ä‡πà‡∏ß‡∏¢‡πÉ‡∏´‡πâ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÑ‡∏°‡πà‡∏™‡∏±‡∏ö‡∏™‡∏ô‡∏Ñ‡πà‡∏≤ BMI ‡∏ó‡∏µ‡πà‡∏™‡∏π‡∏á‡∏Å‡∏ß‡πà‡∏≤‡∏Ñ‡πà‡∏≤ Sensor ‡∏°‡∏≤‡∏Å‡πÜ

scaler = StandardScaler()

# ‡πÅ‡∏õ‡∏•‡∏á 3D (Samples, Time, Features) -> 2D (Samples*Time, Features) ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ Scaler ‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡πÑ‡∏î‡πâ
N_train, T, F = X_train.shape
X_train_reshaped = X_train.reshape(-1, F)
X_train_scaled = scaler.fit_transform(X_train_reshaped) # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏™‡∏π‡∏ï‡∏£‡∏à‡∏≤‡∏Å Train Set
X_train = X_train_scaled.reshape(N_train, T, F)         # ‡πÅ‡∏õ‡∏•‡∏á‡∏Å‡∏•‡∏±‡∏ö‡πÄ‡∏õ‡πá‡∏ô 3D

# ‡πÉ‡∏ä‡πâ‡∏™‡∏π‡∏ï‡∏£‡πÄ‡∏î‡∏¥‡∏° (‡∏à‡∏≤‡∏Å Train) ‡∏°‡∏≤‡∏õ‡∏£‡∏±‡∏ö Test Set (‡∏´‡πâ‡∏≤‡∏° Fit ‡πÉ‡∏´‡∏°‡πà‡∏Å‡∏±‡∏ö Test)
N_test, T, F = X_test.shape
X_test_reshaped = X_test.reshape(-1, F)
X_test = scaler.transform(X_test_reshaped).reshape(N_test, T, F)

print("‚úÖ Data Normalized (Scaled) ‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡∏£‡πâ‡∏≠‡∏¢! (‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÄ‡∏ó‡∏£‡∏ô‡πÅ‡∏•‡πâ‡∏ß)")

# ==========================================
# 3. BUILD MODEL
# ==========================================
model = Sequential()

# CNN Layers (‡∏ï‡∏≤‡∏î‡∏π Pattern)
model.add(Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(WINDOW_SIZE, 4)))
model.add(Conv1D(filters=64, kernel_size=3, activation='relu'))
model.add(Dropout(0.5))
model.add(MaxPooling1D(pool_size=2))

# LSTM Layers (‡∏™‡∏°‡∏≠‡∏á‡∏à‡∏≥‡∏•‡∏≥‡∏î‡∏±‡∏ö)
model.add(LSTM(100, return_sequences=False))
model.add(Dropout(0.5))

# Output Layers
model.add(Dense(100, activation='relu'))
model.add(Dense(3, activation='softmax'))

model.compile(loss='categorical_crossentropy', optimizer=Adam(learning_rate=LEARNING_RATE), metrics=['accuracy'])

# üî• (‡πÉ‡∏´‡∏°‡πà) ‡πÄ‡∏û‡∏¥‡πà‡∏° Callback: ‡∏ñ‡πâ‡∏≤ Loss ‡πÑ‡∏°‡πà‡∏•‡∏î‡∏•‡∏á 5 ‡∏£‡∏≠‡∏ö ‡πÉ‡∏´‡πâ‡∏•‡∏î Learning Rate ‡∏•‡∏á‡∏Ñ‡∏£‡∏∂‡πà‡∏á‡∏ô‡∏∂‡∏á
reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=0.00001, verbose=1)

# ==========================================
# 4. TRAIN MODEL
# ==========================================
print("\nüöÄ START TRAINING...")
history = model.fit(
    X_train, y_train, 
    epochs=EPOCHS, 
    batch_size=BATCH_SIZE, 
    validation_data=(X_test, y_test), 
    callbacks=[reduce_lr],  # üëà ‡∏™‡∏±‡πà‡∏á‡πÉ‡∏´‡πâ‡πÉ‡∏ä‡πâ‡∏ï‡∏±‡∏ß‡∏ä‡πà‡∏ß‡∏¢‡∏•‡∏î LR
    verbose=1
)

# ==========================================
# 5. EVALUATION & SAVING
# ==========================================
print("\nüìù SAVING RESULTS...")

# 5.1 ‡∏Å‡∏£‡∏≤‡∏ü Accuracy & Loss
plt.figure(figsize=(12, 4))

plt.subplot(1, 2, 1)
plt.plot(history.history['accuracy'], label='Train Acc')
plt.plot(history.history['val_accuracy'], label='Val Acc')
plt.title('Model Accuracy (Normalized)')
plt.legend()

plt.subplot(1, 2, 2)
plt.plot(history.history['loss'], label='Train Loss')
plt.plot(history.history['val_loss'], label='Val Loss')
plt.title('Model Loss (Normalized)')
plt.legend()

plt.tight_layout()
plt.savefig(os.path.join(OUTPUT_DIR, "training_result_v2.png")) # ‡πÄ‡∏ã‡∏ü‡∏ä‡∏∑‡πà‡∏≠‡πÑ‡∏ü‡∏•‡πå v2
plt.show()

# 5.2 Confusion Matrix
y_pred = model.predict(X_test)
y_pred_classes = np.argmax(y_pred, axis=1)
y_true = np.argmax(y_test, axis=1)

print("\n--- Classification Report ---")
print(classification_report(y_true, y_pred_classes, target_names=CLASSES))

plt.figure(figsize=(8, 6))
cm = confusion_matrix(y_true, y_pred_classes)
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=CLASSES, yticklabels=CLASSES)
plt.title('Confusion Matrix (Normalized)')
plt.ylabel('True Label')
plt.xlabel('Predicted Label')

plt.savefig(os.path.join(OUTPUT_DIR, "confusion_matrix_v2.png")) # ‡πÄ‡∏ã‡∏ü‡∏ä‡∏∑‡πà‡∏≠‡πÑ‡∏ü‡∏•‡πå v2
plt.show()

# 5.3 Save Model
model.save(os.path.join(OUTPUT_DIR, "gait_risk_model_v2.h5"))
print(f"\nüíæ ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÄ‡∏ß‡∏≠‡∏£‡πå‡∏ä‡∏±‡∏ô V2 ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à‡∏ó‡∏µ‡πà: {OUTPUT_DIR}")
