import pandas as pd
import os
import tkinter as tk
from tkinter import filedialog
from openpyxl.styles import Font, Alignment, Border, Side, PatternFill
from openpyxl.utils import get_column_letter
import matplotlib.pyplot as plt
import matplotlib.ticker as ticker
import numpy as np
import time


# ==========================================
# ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡∏ü‡∏≠‡∏ô‡∏ï‡πå‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏£‡∏≤‡∏ü
# ==========================================
def set_thai_font():
    if os.name == 'nt':  # Windows
        plt.rcParams['font.family'] = 'Tahoma'
    else:  # Mac / Linux
        plt.rcParams['font.family'] = 'Ayuthaya'
    plt.rcParams['axes.unicode_minus'] = False


# ==========================================
# ‡∏™‡πà‡∏ß‡∏ô‡∏ó‡∏µ‡πà 1: ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡πÅ‡∏•‡∏∞ Normalization
# ==========================================

def calculate_svm(df, prefix):
    """‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì SVM (Raw Magnitude)"""
    cols = [f'{prefix}_X', f'{prefix}_Y', f'{prefix}_Z']
    if all(col in df.columns for col in cols):
        svm_col = f'{prefix}_SVM'
        # ‡∏™‡∏π‡∏ï‡∏£: sqrt(x^2 + y^2 + z^2)
        df[svm_col] = (df[cols[0]] ** 2 + df[cols[1]] ** 2 + df[cols[2]] ** 2) ** 0.5
        return svm_col
    return None


def normalize_series(series):
    """
    Min-Max Normalization: ‡∏õ‡∏£‡∏±‡∏ö‡∏Ñ‡πà‡∏≤‡πÉ‡∏´‡πâ‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô‡∏ä‡πà‡∏ß‡∏á 0 ‡∏ñ‡∏∂‡∏á 1
    ‡∏™‡∏π‡∏ï‡∏£: (X - Min) / (Max - Min)
    """
    if series.max() == series.min():  # ‡∏õ‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô‡∏Å‡∏≤‡∏£‡∏´‡∏≤‡∏£‡∏î‡πâ‡∏ß‡∏¢ 0 ‡∏Å‡∏£‡∏ì‡∏µ‡∏Ñ‡πà‡∏≤‡πÄ‡∏ó‡πà‡∏≤‡∏Å‡∏±‡∏ô‡∏´‡∏°‡∏î
        return series.apply(lambda x: 0.0)
    return (series - series.min()) / (series.max() - series.min())


def parse_time_column(df):
    """‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏ß‡∏•‡∏≤‡πÉ‡∏ô‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏õ‡πá‡∏ô‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ó‡∏µ‡πà 0"""
    if 'Time' not in df.columns: return df.index.to_numpy()
    try:
        time_str = df['Time'].astype(str)

        def time_to_seconds(t_str):
            parts = t_str.strip().split(':')
            if len(parts) == 2:
                return float(parts[0]) * 60 + float(parts[1])
            elif len(parts) == 3:
                return float(parts[0]) * 3600 + float(parts[1]) * 60 + float(parts[2])
            else:
                return 0.0

        seconds_array = time_str.apply(time_to_seconds).to_numpy()
        if len(seconds_array) > 0:
            return seconds_array - seconds_array[0]
        else:
            return df.index.to_numpy()
    except Exception:
        return df.index.to_numpy()


# ==========================================
# ‡∏™‡πà‡∏ß‡∏ô‡∏ó‡∏µ‡πà 2: ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡πÑ‡∏ü‡∏•‡πå‡πÅ‡∏•‡∏∞ Excel
# ==========================================

def get_unique_filename(filepath):
    if not os.path.exists(filepath): return filepath
    base, ext = os.path.splitext(filepath)
    counter = 1
    while True:
        new_filepath = f"{base} ({counter}){ext}"
        if not os.path.exists(new_filepath): return new_filepath
        counter += 1


def format_excel_table(worksheet, min_row, max_row, min_col, max_col):
    thin_border = Border(left=Side(style='thin'), right=Side(style='thin'),
                         top=Side(style='thin'), bottom=Side(style='thin'))
    for row in worksheet.iter_rows(min_row=min_row, max_row=max_row, min_col=min_col, max_col=max_col):
        for cell in row:
            cell.border = thin_border
            cell.alignment = Alignment(horizontal='center', vertical='center')
            if isinstance(cell.value, (int, float)): cell.number_format = '0.0000'
    worksheet.column_dimensions['A'].width = 20
    for col_idx in range(min_col + 1, max_col + 1):
        worksheet.column_dimensions[get_column_letter(col_idx)].width = 16
    header_fill = PatternFill(start_color="D9D9D9", end_color="D9D9D9", fill_type="solid")
    for col_idx in range(min_col, max_col + 1):
        cell = worksheet.cell(row=min_row, column=col_idx)
        cell.font = Font(bold=True);
        cell.fill = header_fill


# ==========================================
# ‡∏™‡πà‡∏ß‡∏ô‡∏ó‡∏µ‡πà 3: ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô Plot ‡∏Å‡∏£‡∏≤‡∏ü (Normalized)
# ==========================================

def plot_normalized_graph(df, filename_base, header_title, time_axis):
    try:
        set_thai_font()
        SMOOTH_WINDOW = 7  # ‡∏Ñ‡πà‡∏≤‡∏Ñ‡∏ß‡∏≤‡∏°‡∏°‡∏ô‡∏Ç‡∏≠‡∏á‡∏Å‡∏£‡∏≤‡∏ü

        fig, axs = plt.subplots(3, 1, figsize=(12, 12))
        # Title ‡∏£‡∏∞‡∏ö‡∏∏‡∏ä‡∏±‡∏î‡πÄ‡∏à‡∏ô‡∏ß‡πà‡∏≤‡πÄ‡∏õ‡πá‡∏ô Normalized
        fig.suptitle(f'Normalized SVM Analysis (0-1 Scale): {header_title}', fontsize=16, fontweight='bold')

        locator = ticker.MaxNLocator(integer=True)  # ‡∏õ‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô Error ‡πÑ‡∏ü‡∏•‡πå‡∏¢‡∏≤‡∏ß

        def smooth_data(series, window):
            return series.rolling(window=window, center=True, min_periods=1).mean()

        # Helper function ‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏ß‡∏≤‡∏î‡πÅ‡∏ï‡πà‡∏•‡∏∞‡πÅ‡∏Å‡∏ô
        def plot_subplot(ax, data_col, color, label_text, title_text):
            if data_col in df.columns:
                # 1. ‡πÉ‡∏ä‡πâ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• Normalized
                data_to_plot = df[data_col]
                # 2. ‡∏ó‡∏≥ Smoothing
                smoothed = smooth_data(data_to_plot, SMOOTH_WINDOW)

                ax.plot(time_axis, smoothed, color=color, label=f'Norm SVM (Smooth={SMOOTH_WINDOW})', linewidth=1.5)
                ax.set_ylabel('Norm. Mag (0-1)')  # ‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡∏´‡∏ô‡πà‡∏ß‡∏¢‡πÄ‡∏õ‡πá‡∏ô 0-1
                ax.set_title(title_text, fontsize=12)
                ax.set_xlabel('Time (seconds)')
                ax.set_ylim(-0.05, 1.05)  # ‡∏•‡πá‡∏≠‡∏Ñ‡πÅ‡∏Å‡∏ô Y ‡πÉ‡∏´‡πâ‡πÄ‡∏´‡πá‡∏ô 0 ‡∏ñ‡∏∂‡∏á 1 ‡∏ä‡∏±‡∏î‡πÜ
                ax.xaxis.set_major_locator(locator)
                ax.grid(True, linestyle='--', alpha=0.6)
                ax.legend(loc='upper right')

        # Plot ACC (Normalized)
        plot_subplot(axs[0], 'ACC_SVM_Norm', 'blue', 'ACC', 'Accelerometer: Normalized Pattern (‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏£‡πà‡∏á)')

        # Plot GYRO (Normalized)
        plot_subplot(axs[1], 'GYRO_SVM_Norm', 'green', 'GYRO', 'Gyroscope: Normalized Pattern (‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏Å‡∏≤‡∏£‡∏´‡∏°‡∏∏‡∏ô)')

        # Plot MAG (Normalized)
        plot_subplot(axs[2], 'MAG_SVM_Norm', 'red', 'MAG', 'Magnetometer: Normalized Pattern (‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡πÅ‡∏°‡πà‡πÄ‡∏´‡∏•‡πá‡∏Å)')

        plt.tight_layout(rect=[0, 0.03, 1, 0.96], h_pad=3.0)

        # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÄ‡∏õ‡πá‡∏ô‡∏ä‡∏∑‡πà‡∏≠ _norm_plot ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÅ‡∏¢‡∏Å‡∏Å‡∏±‡∏ö‡∏Å‡∏£‡∏≤‡∏ü‡πÄ‡∏Å‡πà‡∏≤
        image_filename = filename_base + '_norm_plot.png'
        plt.savefig(image_filename)
        plt.close()
        return image_filename
    except Exception as e:
        print(f"   ‚ö†Ô∏è ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Å‡∏£‡∏≤‡∏ü‡πÑ‡∏î‡πâ: {e}")
        return None


# ==========================================
# ‡∏™‡πà‡∏ß‡∏ô‡∏ó‡∏µ‡πà 4: Logic ‡∏´‡∏•‡∏±‡∏Å (Rename + Analyze)
# ==========================================

def batch_rename_mode():
    print("\n" + "=" * 60);
    print("   üìÇ ‡πÇ‡∏´‡∏°‡∏î‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡∏ä‡∏∑‡πà‡∏≠‡πÑ‡∏ü‡∏•‡πå‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥");
    print("=" * 60)
    root = tk.Tk();
    root.withdraw();
    root.attributes('-topmost', True)
    file_paths = filedialog.askopenfilenames(title="‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÑ‡∏ü‡∏•‡πå CSV", filetypes=[("CSV Files", "*.csv")])
    if not file_paths: return

    files_with_time = [(f, os.path.getmtime(f)) for f in file_paths]
    files_with_time.sort(key=lambda x: x[1])

    base_name = input("‡∏ï‡∏±‡πâ‡∏á‡∏ä‡∏∑‡πà‡∏≠‡∏Å‡∏•‡∏∏‡πà‡∏°‡πÑ‡∏ü‡∏•‡πå‡πÉ‡∏´‡∏°‡πà (‡πÄ‡∏ä‡πà‡∏ô Patient_A): ").strip() or "Data"
    count = 0
    for i, (old_path, timestamp) in enumerate(files_with_time, 1):
        directory = os.path.dirname(old_path)
        new_filename = f"{base_name}_{i:02d}{os.path.splitext(old_path)[1]}"
        new_path = os.path.join(directory, new_filename)
        try:
            if old_path != new_path:
                os.rename(old_path, new_path)
                print(f"   ‚úî {os.path.basename(old_path)} -> {new_filename}")
                count += 1
        except Exception as e:
            print(f"Error: {e}")
    print(f"üéâ ‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏¥‡πâ‡∏ô {count} ‡πÑ‡∏ü‡∏•‡πå!");
    input("‡∏Å‡∏î Enter ‡∏Å‡∏•‡∏±‡∏ö‡πÄ‡∏°‡∏ô‡∏π...")


def get_experiment_info():
    scenarios = ["‡∏Å‡∏£‡∏ì‡∏µ‡πÄ‡∏î‡∏¥‡∏ô‡∏õ‡∏Å‡∏ï‡∏¥", "‡∏Å‡∏£‡∏ì‡∏µ‡πÄ‡∏î‡∏¥‡∏ô‡∏õ‡∏Å‡∏ï‡∏¥‡∏ä‡πâ‡∏≤", "‡∏Å‡∏£‡∏ì‡∏µ‡πÄ‡∏î‡∏¥‡∏ô‡πÄ‡∏≠‡∏µ‡∏¢‡∏á‡∏Ç‡∏ß‡∏≤", "‡∏Å‡∏£‡∏ì‡∏µ‡πÄ‡∏î‡∏¥‡∏ô‡πÄ‡∏≠‡∏µ‡∏¢‡∏á‡∏ã‡πâ‡∏≤‡∏¢", "‡∏Å‡∏£‡∏ì‡∏µ‡πÄ‡∏î‡∏¥‡∏ô‡πÄ‡∏≠‡∏µ‡∏¢‡∏á‡∏ã‡πâ‡∏≤‡∏¢‡∏Ç‡∏ß‡∏≤",
                 "‡∏Å‡∏£‡∏ì‡∏µ‡πÄ‡∏î‡∏¥‡∏ô‡∏´‡∏¢‡∏∏‡∏î‡∏ä‡∏∞‡∏á‡∏±‡∏Å"]
    print("\n--- ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏™‡∏ñ‡∏≤‡∏ô‡∏Å‡∏≤‡∏£‡∏ì‡πå ---")
    for i, s in enumerate(scenarios, 1): print(f" [{i}] {s}")
    while True:
        c = input("‡πÄ‡∏•‡∏∑‡∏≠‡∏Å (1-6): ").strip()
        if c.isdigit() and 1 <= int(c) <= 6: return f"{scenarios[int(c) - 1]} : {input('‡∏ä‡∏∑‡πà‡∏≠‡∏ú‡∏π‡πâ‡∏ó‡∏î‡∏•‡∏≠‡∏á: ').strip()}"


def process_sensor_file(file_path, header_title, current_idx, total_files):
    filename = os.path.basename(file_path)
    print(f"\n[{current_idx}/{total_files}] üìÑ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•: {filename}")
    try:
        df = pd.read_csv(file_path)
        elapsed_time = parse_time_column(df)

        # 1. ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì Raw SVM ‡πÅ‡∏•‡∏∞ 2. ‡∏™‡∏£‡πâ‡∏≤‡∏á Normalized SVM Column
        svm_cols = []
        for sensor in ['ACC', 'GYRO', 'MAG']:
            raw_col = calculate_svm(df, sensor)  # ‡πÑ‡∏î‡πâ ACC_SVM
            if raw_col:
                svm_cols.append(raw_col)
                # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡πÉ‡∏´‡∏°‡πà ‡πÄ‡∏ä‡πà‡∏ô ACC_SVM_Norm
                norm_col = f'{raw_col}_Norm'
                df[norm_col] = normalize_series(df[raw_col])

        # ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ó‡∏µ‡πà‡∏à‡∏∞‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥ (‡πÄ‡∏≠‡∏≤‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏Ñ‡πà‡∏≤‡∏à‡∏£‡∏¥‡∏á ‡πÑ‡∏°‡πà‡πÄ‡∏≠‡∏≤ Norm ‡πÄ‡∏û‡∏£‡∏≤‡∏∞‡∏î‡∏π‡∏¢‡∏≤‡∏Å‡πÉ‡∏ô‡∏ï‡∏≤‡∏£‡∏≤‡∏á)
        target_stats_cols = [
            'ACC_X', 'ACC_Y', 'ACC_Z', 'ACC_SVM',
            'GYRO_X', 'GYRO_Y', 'GYRO_Z', 'GYRO_SVM',
            'MAG_X', 'MAG_Y', 'MAG_Z', 'MAG_SVM'
        ]
        valid_stats_cols = [c for c in target_stats_cols if c in df.columns]

        if not valid_stats_cols:
            print("   ‚ùå ‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•")
            return

        # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥ (Mean, Max, Min ‡∏Ç‡∏≠‡∏á‡∏Ñ‡πà‡∏≤‡∏à‡∏£‡∏¥‡∏á ‡∏´‡∏ô‡πà‡∏ß‡∏¢ g/deg)
        stats_data = {}
        for col in valid_stats_cols:
            series = pd.to_numeric(df[col], errors='coerce')
            stats_data[col] = {
                'Mean': series.mean(), 'Median': series.median(), 'SD': series.std(),
                'Skewness': series.skew(), 'Kurtosis': series.kurt(),
                'Max': series.max(), 'Min': series.min()
            }
        summary_df = pd.DataFrame(stats_data)

        # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å Excel
        base_filename_full = os.path.splitext(file_path)[0] + '_summary.xlsx'
        final_excel_filename = get_unique_filename(base_filename_full)
        final_base_name = os.path.splitext(final_excel_filename)[0]

        start_row = 3
        with pd.ExcelWriter(final_excel_filename, engine='openpyxl') as writer:
            # Save Raw Data ‡∏£‡∏ß‡∏°‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå Norm ‡πÑ‡∏õ‡∏î‡πâ‡∏ß‡∏¢‡πÄ‡∏ú‡∏∑‡πà‡∏≠‡∏≠‡∏¢‡∏≤‡∏Å‡∏î‡∏π
            df.to_excel(writer, sheet_name='Raw Data', index=False)
            summary_df.to_excel(writer, sheet_name='Summary Stats', startrow=start_row - 1)

            ws = writer.sheets['Summary Stats']
            ws['A1'] = "‡∏Å‡∏≤‡∏£‡∏ó‡∏î‡∏•‡∏≠‡∏á:";
            ws['B1'] = header_title
            ws['A1'].font = Font(bold=True, size=12);
            ws['B1'].font = Font(bold=True, size=12)
            ws['D1'] = "Graph Type: Normalized (0-1)";
            ws['D1'].font = Font(italic=True, color="555555")

            max_r = start_row + summary_df.shape[0];
            max_c = summary_df.shape[1] + 1
            format_excel_table(ws, min_row=start_row, max_row=max_r, min_col=1, max_col=max_c)
        print(f"   ‚úî Excel (Stats from Raw Data): {os.path.basename(final_excel_filename)}")

        # ‡∏ß‡∏≤‡∏î‡∏Å‡∏£‡∏≤‡∏ü (‡πÉ‡∏ä‡πâ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• Normalized)
        image_file = plot_normalized_graph(df, final_base_name, header_title, elapsed_time)
        if image_file: print(f"   ‚úî Graph (Normalized 0-1): {os.path.basename(image_file)}")

    except Exception as e:
        print(f"   ‚ùå Error: {e}")


def analyze_data_mode():
    title = get_experiment_info()
    root = tk.Tk();
    root.withdraw();
    root.attributes('-topmost', True)
    paths = filedialog.askopenfilenames(title="‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÑ‡∏ü‡∏•‡πå CSV", filetypes=[("CSV Files", "*.csv")])
    if paths:
        print(f"\nüì¶ ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å {len(paths)} ‡πÑ‡∏ü‡∏•‡πå")
        for i, p in enumerate(paths, 1): process_sensor_file(p, title, i, len(paths))
        print("\nüéâ ‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏°‡∏ö‡∏π‡∏£‡∏ì‡πå!");
        input("‡∏Å‡∏î Enter ‡∏Å‡∏•‡∏±‡∏ö‡πÄ‡∏°‡∏ô‡∏π...")


if __name__ == "__main__":
    while True:
        print("\n=== Sensor Analysis (Normalized SVM) ===")
        print(" [1] ‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡∏ä‡∏∑‡πà‡∏≠‡πÑ‡∏ü‡∏•‡πå (Batch Rename)")
        print(" [2] ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• (Normalize + Plot)")
        print(" [0] ‡∏≠‡∏≠‡∏Å")
        c = input("‡πÄ‡∏•‡∏∑‡∏≠‡∏Å: ").strip()
        if c == '1':
            batch_rename_mode()
        elif c == '2':
            analyze_data_mode()
        elif c == '0':
            break